{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library\n",
    "We are using the Turi Create library for implementing the Random Forest Classification Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import turicreate as tc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "We will be using the same given [LendingClub](https://www.lendingclub.com/) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans = tc.SFrame('../data/lending-club-data.sframe/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Column Definition\n",
    "\n",
    "The target column (label column) of the dataset that we are interested in is called `bad_loans`. In this column **1** means a risky (bad) loan **0** means a safe  loan.\n",
    "\n",
    "We reassign the target to be:\n",
    "* **+1** as a safe  loan, \n",
    "* **-1** as a risky (bad) loan. \n",
    "\n",
    "We put this in a new column called `safe_loans` and define it as `target` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans['safe_loans'] = loans['bad_loans'].apply(lambda x : +1 if x==0 else -1)\n",
    "loans = loans.remove_column('bad_loans')\n",
    "\n",
    "target = 'safe_loans' # prediction target (y) (+1 means safe, -1 is risky)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Selection\n",
    "Like previous assignment, we will be using a subset of features (categorical and numeric). The features we will be using are **described in the code comments** below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['grade',                     # grade of the loan\n",
    "            'sub_grade',\n",
    "            'short_emp',                 # one year or less of employment\n",
    "            'emp_length_num',            # number of years of employment\n",
    "            'home_ownership',            # home_ownership status: own, mortgage or rent\n",
    "            'term',                      # the term of the loan\n",
    "            'last_delinq_none',          # has borrower had a delinquincy\n",
    "            'last_major_derog_none',     # has borrower had 90 day or worse rating\n",
    "           ]\n",
    "\n",
    "                  \n",
    "# Extract the feature columns and target column\n",
    "loans = loans[features + [target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Balancing\n",
    "One way to combat class imbalance is to undersample the larger class until the class distribution is approximately half and half. Here, we will undersample the larger class (safe loans) in order to balance out our dataset. This means we are throwing away many data points. We used `seed=1` so everyone gets the same results.\n",
    "\n",
    "We do this in order to help the algorithm studies both classes equally so it can perform more precise predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_loans_raw = loans[loans[target] == +1]\n",
    "risky_loans_raw = loans[loans[target] == -1]\n",
    "\n",
    "# Since there are fewer risky loans than safe loans, find the ratio of the sizes\n",
    "# and use that percentage to undersample the safe loans.\n",
    "percentage = len(risky_loans_raw)/float(len(safe_loans_raw))\n",
    "\n",
    "risky_loans = risky_loans_raw\n",
    "safe_loans = safe_loans_raw.sample(percentage, seed = 1)\n",
    "\n",
    "# Append the risky_loans with the downsampled version of safe_loans\n",
    "loans_data = risky_loans.append(safe_loans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting\n",
    "80% of the original data will be randomly split into training set `(train_data)` and 20% will be randomly split into test set `(test_data)`. We used `seed=1` so everyone gets the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = loans_data.random_split(.8, seed = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model Building\n",
    "By using Turi Create we use its `random_forest_classifier` class to create the model. The parameters are:\n",
    "\n",
    "* `train_data`: the input data for the algorithm to train on.\n",
    "\n",
    "* `validation_set`: set to None because we don't have a validation set.\n",
    "\n",
    "* `target`: is the target column which is `safe_loans`.\n",
    "\n",
    "* `features`: are the features the algorithm will use to learn.\n",
    "\n",
    "* `max_iterations`: the number of trees grown for the model **(this will be covered in the algorithm explaination below)**\n",
    "\n",
    "* `max_depth`: the maximum depth allowed for all trees\n",
    "\n",
    "* `random_seed`: this is the seed for randomization when selecting data points as training data for different trees and subset features for each tree **(this will be covered in the algorithm explaination below)**. For now if you set it to None (`random_seed = None`), the accuracy will be different each time you build the model. If you set it to a fixed number (e.g. `random_seed = 1`), the result for each build will be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Random forest classifier:</pre>"
      ],
      "text/plain": [
       "Random forest classifier:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 37224</pre>"
      ],
      "text/plain": [
       "Number of examples          : 37224"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 8</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 8</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+--------------+-------------------+-------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+--------------+-------------------+-------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Elapsed Time | Training Accuracy | Training Log Loss |</pre>"
      ],
      "text/plain": [
       "| Iteration | Elapsed Time | Training Accuracy | Training Log Loss |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+--------------+-------------------+-------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+--------------+-------------------+-------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 0.022875     | 0.608478          | 0.656767          |</pre>"
      ],
      "text/plain": [
       "| 1         | 0.022875     | 0.608478          | 0.656767          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2         | 0.039619     | 0.619278          | 0.649483          |</pre>"
      ],
      "text/plain": [
       "| 2         | 0.039619     | 0.619278          | 0.649483          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 3         | 0.055099     | 0.622233          | 0.647170          |</pre>"
      ],
      "text/plain": [
       "| 3         | 0.055099     | 0.622233          | 0.647170          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 4         | 0.071007     | 0.623522          | 0.645950          |</pre>"
      ],
      "text/plain": [
       "| 4         | 0.071007     | 0.623522          | 0.645950          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 5         | 0.088552     | 0.623818          | 0.645878          |</pre>"
      ],
      "text/plain": [
       "| 5         | 0.088552     | 0.623818          | 0.645878          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 10        | 0.165495     | 0.624382          | 0.645989          |</pre>"
      ],
      "text/plain": [
       "| 10        | 0.165495     | 0.624382          | 0.645989          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 50        | 0.801629     | 0.625081          | 0.645634          |</pre>"
      ],
      "text/plain": [
       "| 50        | 0.801629     | 0.625081          | 0.645634          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 100       | 1.585504     | 0.625591          | 0.645383          |</pre>"
      ],
      "text/plain": [
       "| 100       | 1.585504     | 0.625591          | 0.645383          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+--------------+-------------------+-------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+--------------+-------------------+-------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_forest_model = tc.random_forest_classifier.create(train_data,\n",
    "                                                            validation_set = None,\n",
    "                                                            target = target,\n",
    "                                                            features = features,\n",
    "                                                            max_iterations = 100,\n",
    "                                                            max_depth = 6,\n",
    "                                                            random_seed = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the summary of the model after building:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class                          : RandomForestClassifier\n",
      "\n",
      "Schema\n",
      "------\n",
      "Number of examples             : 37224\n",
      "Number of feature columns      : 8\n",
      "Number of unpacked features    : 8\n",
      "Number of classes              : 2\n",
      "\n",
      "Settings\n",
      "--------\n",
      "Number of trees                : 100\n",
      "Max tree depth                 : 6\n",
      "Training time (sec)            : 1.5858\n",
      "Training accuracy              : 0.6256\n",
      "Training log_loss              : 0.6454\n",
      "Training auc                   : 0.6754\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Comparison With The Decision Tree Model\n",
    "By using the same training data set `(train_data)`. We also build a Decision Tree Model with them same `target` and `features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Decision tree classifier:</pre>"
      ],
      "text/plain": [
       "Decision tree classifier:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>--------------------------------------------------------</pre>"
      ],
      "text/plain": [
       "--------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of examples          : 37224</pre>"
      ],
      "text/plain": [
       "Number of examples          : 37224"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of classes           : 2</pre>"
      ],
      "text/plain": [
       "Number of classes           : 2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of feature columns   : 8</pre>"
      ],
      "text/plain": [
       "Number of feature columns   : 8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Number of unpacked features : 8</pre>"
      ],
      "text/plain": [
       "Number of unpacked features : 8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+--------------+-------------------+-------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+--------------+-------------------+-------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Iteration | Elapsed Time | Training Accuracy | Training Log Loss |</pre>"
      ],
      "text/plain": [
       "| Iteration | Elapsed Time | Training Accuracy | Training Log Loss |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+--------------+-------------------+-------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+--------------+-------------------+-------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1         | 0.015912     | 0.624248          | 0.645524          |</pre>"
      ],
      "text/plain": [
       "| 1         | 0.015912     | 0.624248          | 0.645524          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-----------+--------------+-------------------+-------------------+</pre>"
      ],
      "text/plain": [
       "+-----------+--------------+-------------------+-------------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decision_tree_model = tc.decision_tree_classifier.create(train_data,\n",
    "                                                            validation_set = None,\n",
    "                                                            target = target,\n",
    "                                                            features = features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, have a quick comparison between two models with their corresponding accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree model's accuracy: 0.6209607927617407\n",
      "Random Forest model's accuracy: 0.6210685049547608\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision Tree model's accuracy:\", decision_tree_model.evaluate(test_data)['accuracy'])\n",
    "print(\"Random Forest model's accuracy:\", random_forest_model.evaluate(test_data)['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that **most of the time** (with `random_seed = None` when building the model), the accuracy of the **Random Forest model** is ***higher*** than the **Decision Tree model**.\n",
    "\n",
    "If your result is opposite, you can try **rebuild** the **Random Forest model** by executing its code cell again. Then try the accuracy test again (or just hit **Run All**)\n",
    "\n",
    "The result will be 100% different each try (with `random_seed = None` when building the model). So how does this work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Random Forest Model Algorithm Explaination**\n",
    "\n",
    "### **Main Idea**\n",
    "The final prediction of this model is based on a combination of multiple different decision trees. For binary classification case (the target column is 1 or 2), it will choose the value with highest amount of predictions among all trees for each prediction.\n",
    "**For example**: let's say we have 5 trees and a data point. Consider the following result by putting the data point through all trees:\n",
    "\n",
    "- Tree 1: predicts 1\n",
    "- Tree 2: predicts 0\n",
    "- Tree 3: predicts 1\n",
    "- Tree 4: predicts 1\n",
    "- Tree 5: predicts 0\n",
    "\n",
    "The final prediction for this data point will be 1 (because 1 has more predictions than 0)\n",
    "\n",
    "But why does it called ***Random***?\n",
    "\n",
    "### **The Learning Process**\n",
    "**Input**: the training data set `train_data`\n",
    "\n",
    "**Learning**: build K trees (the K number here is specified by the parameter `max_iterations` when building the model). For each tree:\n",
    "1. Generate K ***random*** new training sets from the original training set with a method called **Bootstrap Aggregating** or **Bagging** for short. This means ***randomly*** select any item in the original set and append it into the new set until the size of the new set is equal to the old one (duplicates are allowed). For example: The original set is: 1,2,3,4,5. The K new sets would be:\n",
    "    - 1,1,2,3,4\n",
    "    - 2,1,5,5,3\n",
    "    - 4,2,3,1,5\n",
    "    - ...\n",
    "2. We use i<sup>th</sup> new training set for the i<sup>th</sup> tree to learn.\n",
    "3. For each tree, instead of using all features for it, we select ***randomly*** a subset of features with a feature called **Feature Randomness**. The number of features selected will be $\\sqrt{total features}$. According to scientists, this formula usually leads to a more accurate prediction.\n",
    "4. Grow K trees to n depth (is determined by parameter `max_depth`)\n",
    "\n",
    "**Predicting**: the final prediction will be the highest amount of predictions among all trees for each data point.\n",
    "\n",
    "-> Through the learning process, the process in this model evolves ***randomness***. This is why it is called **Random Forest** - Forest here means multiple trees.\n",
    "\n",
    "### **Pros and Cons**\n",
    "**Pros**: Most of the time, it will gives a more accurate and precise prediction compares to original Decision Tree Model. Since there are multiple trees and they are randomly different from each other, it avoids and prevents the overfitting problem with the original model.\n",
    "\n",
    "**Cons**: Consumes more computation power and time. There are more trees to be built even with less features for each of them.\n",
    "\n",
    "\n",
    "\n",
    "**Visualized Reference From**\n",
    "https://www.youtube.com/watch?v=v6VJ2RO66Ag&list=LL&index=1&ab_channel=NormalizedNerd\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
